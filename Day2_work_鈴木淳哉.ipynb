{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [通し課題]\n",
    "\n",
    "8. DAY2、3で学んだことの取り組み • 交差検証、ホールドアウト法などで汎化性能を確認する  \n",
    " • 欠測値と異常値を確認し、適切に処理する  \n",
    " • DAY2、3で学んだアルゴリズムを利用してモデルをつくり、DAY1宿題提出時の精度と比較する  \n",
    " • 交差検証によるパラメータチューニングを行う  \n",
    " • パラメータチューニング後のモデルによって、精度および結果の評価を行う  \n",
    " • その他、精度の向上ができるような処理に取り組み、精度を上げる  \n",
    " • できたところまでをNotebookでまとめ、宿題として提出する  \n",
    " • 前回から取り組んだ内容・工夫、精度がどのように変化したかのコメントを Notebookに含めること  \n",
    " • 15分程度，受講者同士で通し課題の進捗を見せ合う時間を設けます  \n",
    "9. DAY4では、DAY3宿題の提出ファイルを元に、最終発表を実施いただ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. DAY1での実施事項\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2996 19902\n",
      "103320 80771\n",
      "Accuracy  = 88.938%\n",
      "Recall    = 96.423%\n",
      "Precision = 80.231%\n"
     ]
    }
   ],
   "source": [
    "#********************************************************************\n",
    "# pandas,numpy,matplotlib,codecs,sklearnの各ライブラリをインポート\n",
    "#********************************************************************\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs as cd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "#********************************************************************\n",
    "#.該当課題のデータを読み込む\n",
    "#********************************************************************\n",
    "#201801のデータを読み込んでみる\n",
    "with cd.open('ks-projects-201801.csv', 'r', 'utf-8', 'ignore') as f18:\n",
    "    df_f18 = pd.read_csv(f18)\n",
    "#df_f18 = pd.read_csv('ks-projects-201801.csv')\n",
    "\n",
    "#********************************************************************\n",
    "#.欠損値がある行は、とりあえずなくしてみる\n",
    "#********************************************************************\n",
    "#１個でも欠損値がある行はとりあえず削除してみる。\n",
    "df_f18_dna = df_f18.dropna(how='any')\n",
    "\n",
    "#********************************************************************\n",
    "#.成功（'successful'）と失敗（'failed'）に絞って考える。\n",
    "#********************************************************************\n",
    "#成功だけを抽出したDFと失敗だけを抽出したDF\n",
    "df_f18_success = df_f18_dna[df_f18_dna['state']=='successful']\n",
    "df_f18_failed =  df_f18_dna[df_f18_dna['state']=='failed']\n",
    "#両方を結合\n",
    "df_f18_SorF = pd.concat([df_f18_success,df_f18_failed])\n",
    "\n",
    "#********************************************************************\n",
    "#.'state'をカテゴリ変数（文字列）から数値化してみる。\n",
    "#********************************************************************\n",
    "#LabelEncoderのインスタンスを生成\n",
    "le = LabelEncoder()\n",
    "\n",
    "#stateに出てくるカテゴリを覚えて\n",
    "#stateを数値に変換\n",
    "le = le.fit(df_f18_SorF['state'])\n",
    "df_f18_SorF['state'] = le.transform(df_f18_SorF['state'])\n",
    "\n",
    "#********************************************************************\n",
    "#.ロジスティック回帰で分類してみる。\n",
    "#　「goal」、「backers」を有効そうな説明変数とする。\n",
    "#********************************************************************\n",
    "#目的変数'state'を正解としてyに格納\n",
    "y = df_f18_SorF['state'].values\n",
    "#説明変数'goal','backers'を入力としてXに格納\n",
    "X = df_f18_SorF[['goal', 'backers']].values\n",
    "\n",
    "#ロジスティック回帰で学習\n",
    "clf = SGDClassifier(loss='log', penalty='none', max_iter=10000, fit_intercept=True, random_state=1234)\n",
    "clf.fit(X, y)\n",
    "\n",
    "#********************************************************************\n",
    "#.予測精度または識別精度を確認する\n",
    "#　混同行列を作成し、Accuracy、Recall、Precisionを求める\n",
    "#********************************************************************\n",
    "# 学習した結果を使って説明変数を入力して予測\n",
    "y_est = clf.predict(X)\n",
    "\n",
    "#混同行列を作成\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_est).ravel()\n",
    "print(fn, fp)\n",
    "print(tn, tp)\n",
    "\n",
    "#'Accuracy、Recall、Precisionを求めて表示\n",
    "print('Accuracy  = {:.3f}%'.format(100 * (tn+tp)/(tn+fp+fn+tp)))\n",
    "print('Recall    = {:.3f}%'.format(100 * (tp)/(fn+tp)))\n",
    "print('Precision = {:.3f}%'.format(100 * (tp)/(fp+tp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# １．交差検証、ホールドアウト法などで汎化性能を確認する  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.1. 欠測値と異常値を確認し、適切に処理する "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2. DAY2、3で学んだアルゴリズムを利用してモデルをつくり、DAY1宿題提出時の精度と比較する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. 交差検証によるパラメータチューニングを行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. パラメータチューニング後のモデルによって、精度および結果の評価を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. その他、精度の向上ができるような処理に取り組み、精度を上げる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. できたところまでをNotebookでまとめ、宿題として提出する  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. 前回から取り組んだ内容・工夫、精度がどのように変化したかのコメントを Notebookに含めること "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. 15分程度，受講者同士で通し課題の進捗を見せ合う時間を設けます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
